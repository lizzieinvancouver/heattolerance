?phylomatic_local
taxa <- c("Poa annua", "Phlox diffusa", "Helianthus annuus")#
(tree <- phylomatic_local(taxa, path = "~/Desktop/forJD/phylomatic-ws"))#
plot(tree, no.margin=TRUE)
library(brranching)
?phylomatic_local
taxa <- c("Poa annua", "Phlox diffusa", "Helianthus annuus")#
(tree <- phylomatic_local(taxa, path = "~/Desktop/forJD/phylomatic-ws"))
library(brranching)
?phylomatic_local
tree <- phylomatic_local(taxa, path = "~/Desktop/forJD/phylomatic-ws", clean = FALSE))
tree <- phylomatic_local(taxa, path = "~/Desktop/forJD/phylomatic-ws", clean = FALSE)
taxa <- c("Poa annua", "Phlox diffusa", "Helianthus annuus")
(tree <- phylomatic_local(taxa, path = "~/Desktop/forJD/phylomatic-ws")
)
library(caper)
head(shorebird)
data(shorebird)
head(shorebird)
shorebird
?shorebird
head(shorebird.data)
hist(M.Mass)
hist(shorebird.data$M.Mass)
hist(c(shorebird.data$M.Mass, shorebird.data$F.Mass )
)
hist(shorebird.data$F.Mass)
hist(shorebird.data$Egg.Mass)
hist(shorebird.data$F.Mass)
hist(shorebird.data$M.Mass)
hist(shorebird.data$Egg.Mass)
hist(shorebird.data$M.Mass)
hist(shorebird.data$F.Mass)
hist(shorebird.data$F.Mass, breaks=100)
hist(shorebird.data$F.Mass, breaks=10)
hist(shorebird.data$F.Mass, breaks=20)
plot(F.Mass~Mat.syst, data=shorebird.data)
plot(F.Mass~CL.size, data=shorebird.data)
plot(F.Mass~Cl.size, data=shorebird.data)
require(nlme)#
require(ape)#
require(phytools)#
require(geiger)#
# Phylogenetic simulations ------------------------------------------------#
#
####
# Parameters for the phylogenetic simulations#
#
nspecies=10#
nindividuals=10#
# Give a relative scale to the species tree vs. the infraspecific tree.#
# The total tree length is fixed to 1.#
species.scale=0.9 #Total#
infrasp.scale=1-species.scale#
# Pagel's lambda parameter, to give more or less importance to the#
# phylogenetic relationships#
lambda = 1.0#
#
####
# Simulate species tree#
#
spetree <- pbtree(n=nspecies,nsim=1,b=1,complete=FALSE,scale=species.scale)#
#rename tips to be able to find them below...#
tips<-c("sp1","sp2","sp3","sp4","sp5","sp6","sp7","sp8","sp9","sp10")#
spetree$tip.label <- tips#
plot(spetree);add.scale.bar()#
#
####
# Simulate individual trees, one per species#
#
# Here, extinction = 0#
poptrees <- pbtree(n=nindividuals,nsim=nspecies,b=1,scale=infrasp.scale)#
#
####
# Stich trees together#
#
combtree<-spetree#
for(i in 1:length(spetree$tip.label)){#
  newtips <- paste(letters[i],seq(1,length(poptrees[[i]]$tip.label)),sep="")#
  poptrees[[i]]$tip.label <- newtips#
  tipname <- tips[i]#
  tipnumber <- seq(1,length(combtree$tip.label))[combtree$tip.label==tipname]#
  poptrees[[i]]$root.edge<-0#
  combtree<- bind.tree(combtree,poptrees[[i]],where=tipnumber,position=0)#
}#
plot(combtree,cex=0.5);add.scale.bar()#
#
####
# Create tree with no infraspecific info#
combtree0<-spetree#
for(i in 1:length(spetree$tip.label)){#
  newtips <- paste(letters[i],seq(1,length(poptrees[[i]]$tip.label)),sep="")#
  poptrees[[i]]$tip.label <- newtips#
  #collapse branch lengths#
  poptrees[[i]]$edge.length <- rep(0.0001,length.out=length(poptrees[[i]]$edge.length))#
  tipname <- tips[i]#
  tipnumber <- seq(1,length(combtree0$tip.label))[combtree0$tip.label==tipname]#
  poptrees[[i]]$root.edge<-0#
  combtree0<- bind.tree(combtree0,poptrees[[i]],where=tipnumber,position=0)#
}#
# Scale the whole tree to have length 1#
combtree0$edge.length <- combtree0$edge.length/max(nodeHeights(combtree0)[,2])*1#
plot(combtree0,cex=0.5);add.scale.bar()#
#
####
# Rescale trees#
#
combtree <- rescale(combtree,"lambda",lambda)#
combtree0 <- rescale(combtree0,"lambda",lambda)#
#
# Character simulations -------------------------------------------------#
#
# These follow Revell et al. 2010. MEE#
#
####
# Parameters#
#
n.sp <- length(combtree$tip.label) #number of species#
sigma.sq.x = 1 # Rate of evolution in X#
sigma.sq.e = 0.7 # Rate of residual variation#
B = 0.75 # Regression slope#
C <- vcv.phylo(combtree) # VCV matrix#
u <- rnorm(n=n.sp,mean=10) # Random deviates from the normal distribution #
v <- rnorm(n=n.sp,mean=0) # Random deviates from the normal distribution #
#
####
# Simulate variables#
#
# Get values for the X variable that are phylogeneticaly correlated#
x <- t(chol(C*sigma.sq.x)) %*% u#
#
# Generate residual error that is phylogenetically correlated#
e <- t(chol(C*sigma.sq.e)) %*% v#
#
# Get response variable#
y <- x %*% B + e#
####
# Other options for character simulations#
#
# Get values for the X variable that are NOT phylogeneticaly correlated#
# x <- sqrt(sigma.sq.x) * u#
# Model fitting -----------------------------------------------------------#
#
require(nlme)#
#
# data frame#
thedata <- data.frame(y=y,x=x,sp=gsub("[0-9]*","",combtree$tip.label))#
#
# formula#
f1 <- formula(y~x)#
#
# Phylo correlation#
phylo.corr <- corBrownian(phy=combtree)#
phylo.corr0 <- corBrownian(phy=combtree0) # Tree without infrapsecific branch lengths#
#
# Fit phylogenetic regression with species as random effect#
gls.mod0 <- lme(f1,random = ~1 | sp, data=thedata)#
gls.mod1 <- lme(f1,random = ~1 | sp, correlation = phylo.corr, data=thedata)#
gls.mod2 <- lme(f1,random = ~1 | sp, correlation = phylo.corr0, data=thedata)#
#
# Fit phylogenetic regression WITHOUT species as random effect#
gls.mod3 <- gls(f1,correlation = phylo.corr, data=thedata)#
gls.mod4 <- gls(f1,correlation = phylo.corr0, data=thedata)#
#
# Compare all models#
AIC(gls.mod0,gls.mod1,gls.mod2,gls.mod3,gls.mod4)
setwd("~/Documents/github/genetics/analyses")
library(ggplot2)
goo <- read.csv("~/Desktop/modem.csv", header=TRUE)
ggplot(goo, aes(x=download, fill=vmodem)) + geom_density(alpha=0.45) +
ggplot(goo, aes(x=download, fill=modem)) + geom_density(alpha=0.45)
ggplot(goo, aes(x=upload, fill=modem)) + geom_density(alpha=0.45)
ggplot(goo, aes(x=download, fill=modem)) + geom_density(alpha=0.45)
library(dplyr)#
#
# <> <> <> <> <> <> <> <> <> <> <> <> <> <> <> <> <> <> <> <>#
# Set up: same as experiment, with two sites, 28 species, two levels each of warming and photoperiod, and three levels of chilling. 2016-04-01 adding interactions. This ends up generating expected differences, but variation in effect sizes across species is minimal currently.#
# <> <> <> <> <> <> <> <> <> <> <> <> <> <> <> <> <> <> <> <>#
#
nsite = 2#
nsp = 28#
#
nwarm = 2#
nphoto = 2#
nchill = 3#
#
rep = 10 # within each combination of treatments. #
#
(ntot = nsite*nwarm*nphoto*nchill*rep) # 792 rows; 22k rows across species#
#
# Build up the data frame#
site = gl(nsite, rep, length = ntot)#
#
warm = gl(nwarm, rep*nsite, length = ntot)#
photo = gl(nphoto, rep*nsite*nwarm, length = ntot)#
chill = gl(nchill, rep*nsite*nwarm*nphoto, length = ntot)#
#
chill1 = ifelse(chill == 2, 1, 0) #
chill2 = ifelse(chill == 3, 1, 0) #
#
treatcombo = paste(warm, photo, chill1, chill2, sep = "_")#
#
(d <- data_frame(site, warm, photo, chill1, chill2, treatcombo))#
#
###### Set up differences for each level#
sitediff = 2 #
warmdiff = -20 # days earlier from 1 to 2#
photodiff = -14#
chill1diff = -20#
chill2diff = -19#
#
# interactions. 9 two-way interactions#
sitewarm = 0#
sitephoto = 0#
sitechill1 = -1 # similar to stan results#
sitechill2 = -2#
warmphoto = 3.5 # positive 3.5. So at the warm level, the effect of longer days is muted by 3.5 days.#
warmchill1 = 11 # both positive ~ 10. #
warmchill2 = 9#
photochill1 = 0.1 # from stan results#
photochill2 = 1#
#
######## SD for each treatment#
sitediff.sd = 1.5 #
warmdiff.sd = 1 #
photodiff.sd = 1#
chill1diff.sd = 1.5#
chill2diff.sd = 2#
#
# interactions. 9 two-way interactions#
sitewarm.sd = 1#
sitephoto.sd = 1#
sitechill1.sd = 2 #
sitechill2.sd = 2#
warmphoto.sd = 1#
warmchill1.sd = 1.5#
warmchill2.sd = 1.5#
photochill1.sd = 1#
photochill2.sd = 1
mm <- model.matrix(~(site+warm+photo+chill1+chill2)^2, data.frame(site, warm, photo))
mm
mm <- model.matrix(~(site+warm+photo+chill1+chill2)^2, data.frame(site, warm, photo))#
# remove last column, chill1 x chill2, empty#
mm <- mm[,-grep("chill1:chill2", colnames(mm))]#
colnames(mm)#
#
coeff <- c(1, sitediff, warmdiff, photodiff, chill1diff, chill2diff, #
           sitewarm, sitephoto, sitechill1, sitechill2,#
           warmphoto, warmchill1, warmchill2,#
           photochill1, photochill2#
)
coeff
head(warm)
tolower("Climatic Changes Lead to Declining Winter Chill for Fruit and Nut Trees in California during 1950-2099")
tolower("AMPELOGRAPHY - AN OLD TECHNIQUE WITH FUTURE USES: THE CASE OF MINOR VARIETIES OF VITIS VINIFERA L. FROM THE BALEARIC ISLANDS")
tolower("STATE OF THE VITIVINICULTURE WORLD MARKET")
37000000000*0.05
37000000000*0.025
tolower("HOW CAN GRAPEVINE GENETICS CONTRIBUTE TO THE ADAPTATION TO CLIMATE CHANGE?")
rm(list=ls())#
library(ggmap)#
library(ggplot2)#
library(rworldmap)#
library(maps)#
library(mapdata)#
library(marmap)#
##Simple approach#
## map without background#
mapDevice() #create world map shaped window#
map("world", fill=TRUE#
    ,col="grey65"#
    ,boundary=F,interior=F#
    ,ylim=c(-60, 65), mar=c(0,0,0,0)#
    ,projection='albers',par=c(0,0),wrap=T#
    ,resolution=1,border="lightgrey",myborder=0)#
#
## map with blue background#
map("world", fill=TRUE#
    ,col="grey65"#
    ,bg="deepskyblue4"#
    ,boundary=F,interior=F#
    ,ylim=c(-60, 65), mar=c(0,0,0,0)#
    ,projection='albers',par=c(0,0),wrap=T#
    ,resolution=0,border="white",myborder=0)
600*0.85
oeb216 <- c(96.125,94.75,94,92.375,85.25,93.75, 87.625, 97.5)
hist(oeb216)
hist(oeb216, breaks=8)
hist(oeb216, breaks=16)
48-19
oeb216 <- c(96.125,94.75,94,92.375,85.25,93.75, 87.625, 97.5)hist(oeb216, breaks=16)
library(rstan)
rm(list=ls()) #
setwd("/users/kharouba/google drive/UBC/synchrony project/analysis/stan_2016")#
library(rstan)#
library(shinyStan)#
#
#Needed to create parameters#
Nspp<-37 #(Old Nj)#
Nstudy <- 13 # number of studies (old Nk)#
#
######################
# True parameter values#
#a<-1; a[1:Nspp] <- 121.2615 # mean doy - for intercept (OR MU_A)#
#mu_b<- -0.349733 # mean slope from lm fits (based on hinge data)#
#sigma_y <- 42.30465 # sd associated with response, doy#
#sigma_b_spp<-0.737724 #- sd of mean slopes#
#sigma_b_study<-0.2 #NEED TO FIX#
#
mu_a<- 121.2615 # mean doy - for intercept #
sigma_a<-5#
mu_b<- -0.349733 # mean slope from lm fits (based on hinge data) (SAME AS B_YR_0)#
sigma_b<-0.1 #- sd of mean slopes actual=0.737724#
sigma_y <- 42.30465 # sd associated with response, doy#
#
a<-rnorm(Nspp, mu_a, sigma_a);#
b<-rnorm(Nspp, mu_b, sigma_b); #generate slopes for each species#
beta_b_spp<-rnorm(Nspp, mu_b, sigma_b); #generate slopes for each species (OR B)#
mean(beta_b_spp)#
#
# Simulate/create the data#
year_0 <- 1981 # small numbers (like 0) are better than bigger numbers (like 1976)#
n_data_per_study<- round(runif(Nstudy, 2, 4)) # how many sp per study?#
#n_data_per_study<- round(runif(Nk, 2, 8)) # how many sp per study?#
studyid<- rep(1:Nstudy, n_data_per_study) ## Create a vector of study IDs where j-th element gives studyid ID for spp ID j; length of species, every species gets studyid#
studyid<-c(1,1,1,1,2,2,2,3,3,3,3,4,4,4,5,5,5,6,6,7,8,8,9,9,9,10,10,10,10,11,11,11,12,12,13,13,13)#
Nspp <- length(studyid) # creates number of species based on data structure for studyid#
#
#n_data_per_species <- round(runif(Nj, 5, 40)) # how many years per sp.?#
n_data_per_species <- round(runif(Nspp, 10, 10)) # how many years per sp.?#
#
species <- rep(1:Nspp, n_data_per_species) #adds sppid-HK added#
N <- length(species) #nrow of 'dataframe'#
#
uni<-as.data.frame(studyid)#
uni$species<-unique(species)#
uni2<-as.data.frame(species)#
uni3<-merge(uni2, uni, by=c("species"))#
studyid<-uni3$studyid #needs to be same length as number of lowest level/observations
head(studyid)
studyid
unique(species)
######################
year <- rep(NA, N)#
for (j in 1:Nspp){#
  year[species==j] <- rev(2009 - 1:(n_data_per_species[j])) - year_0 #assign 'new' year for each year/row for each species; from first year of study, number of years that differ from 1976, rev:like sort in descending order-HK added, series of years for each spp#
}#
ypred <- length(N) # Lizzie added#
for (i in 1:N){ # actual STAN model#
	s <- species[i] #sppid for each row#
   ypred[i] <- a[species[s]] + beta_b_spp[species[s]]*year[i]; #mean? prediction is a function of vairance associated with species, fits slope with species random slope model, n loop, create data #
}#
y <- rnorm(N, ypred, sigma_y);#
desMat <- model.matrix(object = ~ 1 + year)#
p<-ncol(desMat)#
fit_simple<-stan("stanmodels/threelevelrandomslope2.stan", data=c("N","Nspp","Nstudy","species", "studyid","y","year"), iter=3000, chains=4)
fit_simple<-stan("~/Desktop/huts/threelevelrandomslope2.stan", data=c("N","Nspp","Nstudy","species", "studyid","y","year"), iter=3000, chains=4)
shinyStan(fit_simple)
shinystan(fit_simple)
launch_shinystan(fit_simple)
library(shinystan)
launch_shinystan(fit_simple)
fit_simple<-stan("~/Desktop/huts/threelevelrandomslope2.stan", data=c("N","Nspp","Nstudy","species", "studyid","y","year"), iter=3000, chains=4)
rm(list=ls()) #
setwd("/users/kharouba/google drive/UBC/synchrony project/analysis/stan_2016")#
library(rstan)#
library(shinyStan)#
#
#Needed to create parameters#
Nspp<-37 #(Old Nj)#
Nstudy <- 13 # number of studies (old Nk)#
#
######################
# True parameter values#
#a<-1; a[1:Nspp] <- 121.2615 # mean doy - for intercept (OR MU_A)#
#mu_b<- -0.349733 # mean slope from lm fits (based on hinge data)#
#sigma_y <- 42.30465 # sd associated with response, doy#
#sigma_b_spp<-0.737724 #- sd of mean slopes#
#sigma_b_study<-0.2 #NEED TO FIX#
#
mu_a<- 121.2615 # mean doy - for intercept #
sigma_a<-5#
mu_b<- -0.349733 # mean slope from lm fits (based on hinge data) (SAME AS B_YR_0)#
sigma_b<-0.1 #- sd of mean slopes actual=0.737724#
sigma_y <- 42.30465 # sd associated with response, doy#
#
a<-rnorm(Nspp, mu_a, sigma_a);#
b<-rnorm(Nspp, mu_b, sigma_b); #generate slopes for each species#
beta_b_spp<-rnorm(Nspp, mu_b, sigma_b); #generate slopes for each species (OR B)#
mean(beta_b_spp)#
#
# Simulate/create the data#
year_0 <- 1981 # small numbers (like 0) are better than bigger numbers (like 1976)#
n_data_per_study<- round(runif(Nstudy, 2, 4)) # how many sp per study?#
#n_data_per_study<- round(runif(Nk, 2, 8)) # how many sp per study?#
studyid<- rep(1:Nstudy, n_data_per_study) ## Create a vector of study IDs where j-th element gives studyid ID for spp ID j; length of species, every species gets studyid#
studyid<-c(1,1,1,1,2,2,2,3,3,3,3,4,4,4,5,5,5,6,6,7,8,8,9,9,9,10,10,10,10,11,11,11,12,12,13,13,13)#
Nspp <- length(studyid) # creates number of species based on data structure for studyid#
#
#n_data_per_species <- round(runif(Nj, 5, 40)) # how many years per sp.?#
n_data_per_species <- round(runif(Nspp, 10, 10)) # how many years per sp.?#
#
species <- rep(1:Nspp, n_data_per_species) #adds sppid-HK added#
N <- length(species) #nrow of 'dataframe'#
#
uni<-as.data.frame(studyid)#
uni$species<-unique(species)#
uni2<-as.data.frame(species)#
uni3<-merge(uni2, uni, by=c("species"))#
studyid<-uni3$studyid #needs to be same length as number of lowest level/observations#
######################
year <- rep(NA, N)#
for (j in 1:Nspp){#
  year[species==j] <- rev(2009 - 1:(n_data_per_species[j])) - year_0 #assign 'new' year for each year/row for each species; from first year of study, number of years that differ from 1976, rev:like sort in descending order-HK added, series of years for each spp#
}#
ypred <- length(N) # Lizzie added#
for (i in 1:N){ # actual STAN model#
	s <- species[i] #sppid for each row#
   ypred[i] <- a[species[s]] + beta_b_spp[species[s]]*year[i]; #mean? prediction is a function of vairance associated with species, fits slope with species random slope model, n loop, create data #
}#
y <- rnorm(N, ypred, sigma_y);#
desMat <- model.matrix(object = ~ 1 + year)#
p<-ncol(desMat)#
fit_simple<-stan("~/Desktop/huts/threelevelrandomslope2.stan", data=c("N","Nspp","Nstudy","species", "studyid","y","year"), iter=3000, chains=4)
launch_shinystan(fit_simple)
library(shinystan)
launch_shinystan(fit_simple)
tolower("THE CHRONOLOGICAL CLASSIFICATION OF GRAPEVINE PHENOLOGY")
nreps = 30  #replicate observations per plot#
S = 10     #total number of sites#
J = 4 * S  #total number of plots (4 per site)#
N = 3*4*10 #
#
x <- rgamma(N,5,2)#
#
plotnum <- rep(c(1:J), each=nreps)   #list of plot numbers for each observation (length N)#
sitenum <- rep(c(1:10), each=4)  #list of site numbers for each plot (length J)#
#
#mu_a and sig_a are the mean and variance of the intercept across sites#
mu_a <- 5#
sig_a <- 2#
#mu_b and sig_b are the mean and variance of the slope across sites#
mu_b <- 4#
sig_b <- 1#
#draw S=10 site means for slope and intercept#
a_site <- rnorm(S,mu_a,sig_a)#
b_site <- rnorm(S,mu_b,sig_b)#
#draw S=10 site sds for slope and intercept (variability of plots within sites)#
sig_a_site <- rlnorm(S,0,1)#
sig_b_site <- rlnorm(S,0,1)#
#
#for each plot, draw the slope and intercept from the appropriate site mean and sd#
a_plot <- rep(0,J)#
b_plot <- rep(0,J)#
for (j in 1:J){#
  a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[sitenum[j]]);#
  b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[sitenum[j]]);#
}#
#
#draw three observations from each plot with sd = sig_y#
sig_y <- 1#
y <- rep(0,N)#
for (n in 1:N){#
  yhat <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n]#
  y[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n] + rnorm(1,0,sig_y)#
}#
#
#plot data#
allsites <- rep(c(1:10),each=12) #for plotting, list of site numbers for each obs#
plot(y~x,col=allsites,type='n')#
text(x,y,plotnum, cex=0.5, col=allsites)#
#
#call stan model#
dat <- list(N=N,S=S,J=J,plotnum=plotnum, sitenum=sitenum,y=y,x=x) #
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/threelevel_plotsinsites.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4)
library(rstan)
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/threelevel_plotsinsites.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4)
nreps = 30  #replicate observations per plot#
S = 10     #total number of sites#
J = 4 * S  #total number of plots (4 per site)#
N = nreps*4*10 #
#
x <- rgamma(N,5,2)#
#
plotnum <- rep(c(1:J), each=nreps)   #list of plot numbers for each observation (length N)#
sitenum <- rep(c(1:10), each=4)  #list of site numbers for each plot (length J)#
#
#mu_a and sig_a are the mean and variance of the intercept across sites#
mu_a <- 5#
sig_a <- 2#
#mu_b and sig_b are the mean and variance of the slope across sites#
mu_b <- 4#
sig_b <- 1#
#draw S=10 site means for slope and intercept#
a_site <- rnorm(S,mu_a,sig_a)#
b_site <- rnorm(S,mu_b,sig_b)#
#draw S=10 site sds for slope and intercept (variability of plots within sites)#
sig_a_site <- rlnorm(S,0,1)#
sig_b_site <- rlnorm(S,0,1)#
#
#for each plot, draw the slope and intercept from the appropriate site mean and sd#
a_plot <- rep(0,J)#
b_plot <- rep(0,J)#
for (j in 1:J){#
  a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[sitenum[j]]);#
  b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[sitenum[j]]);#
}#
#
#draw three observations from each plot with sd = sig_y#
sig_y <- 1#
y <- rep(0,N)#
for (n in 1:N){#
  yhat <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n]#
  y[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n] + rnorm(1,0,sig_y)#
}#
#
#plot data#
allsites <- rep(c(1:10),each=12) #for plotting, list of site numbers for each obs#
plot(y~x,col=allsites,type='n')#
text(x,y,plotnum, cex=0.5, col=allsites)
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/threelevel_plotsinsites.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4)
launch_shinystan(fit_simple)
launch_shinystan(fitme)
library(shinystan)
launch_shinystan(fitme)
library(rstan)#
library(shinystan)#
#
nreps = 10  #replicate observations per plot#
S = 10     #total number of sites#
jreps <- 8#
J = jreps * S  #total number of plots (4 per site)#
N = nreps*jreps*S #
#
x <- rgamma(N,5,2)#
#
plotnum <- rep(c(1:J), each=nreps)   #list of plot numbers for each observation (length N)#
sitenum <- rep(c(1:S), each=jreps)  #list of site numbers for each plot (length J)#
#
#mu_a and sig_a are the mean and variance of the intercept across sites#
mu_a <- 5#
sig_a <- 2#
#mu_b and sig_b are the mean and variance of the slope across sites#
mu_b <- 4#
sig_b <- 1#
#draw S=10 site means for slope and intercept#
a_site <- rnorm(S,mu_a,sig_a)#
b_site <- rnorm(S,mu_b,sig_b)#
#draw S=10 site sds for slope and intercept (variability of plots within sites)#
sig_a_site <- rlnorm(S,0,1)#
sig_b_site <- rlnorm(S,0,1)#
#
#for each plot, draw the slope and intercept from the appropriate site mean and sd#
a_plot <- rep(0,J)#
b_plot <- rep(0,J)#
for (j in 1:J){#
  a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[sitenum[j]]);#
  b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[sitenum[j]]);#
}#
#
#draw three observations from each plot with sd = sig_y#
sig_y <- 1#
y <- rep(0,N)#
for (n in 1:N){#
  yhat <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n]#
  y[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n] + rnorm(1,0,sig_y)#
}#
#
#plot data#
allsites <- rep(c(1:10),each=12) #for plotting, list of site numbers for each obs#
plot(y~x,col=allsites,type='n')#
text(x,y,plotnum, cex=0.5, col=allsites)
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/threelevel_plotsinsites.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4, control=list(adapt_delta = 0.9))
launch_shinystan(fitme)
sig_a_site <- rlnorm(S,0,1)
sig_a_site
head(y)
head(yhat)
yhat
sig_y <- 1#
y <- rep(0,N)#
for (n in 1:N){#
  yhat[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n]#
  y[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n] + rnorm(1,0,sig_y)#
}
plot(y~yhat)
hist(a_site)
hist(b_site)
nreps = 10  #replicate observations per plot#
S = 10     #total number of sites#
jreps <- 8#
J = jreps * S  #total number of plots (4 per site)#
N = nreps*jreps*S #
#
x <- rgamma(N,5,2)#
#
plotnum <- rep(c(1:J), each=nreps)   #list of plot numbers for each observation (length N)#
sitenum <- rep(c(1:S), each=jreps)  #list of site numbers for each plot (length J)#
#
#mu_a and sig_a are the mean and variance of the intercept across sites#
mu_a <- 5#
sig_a <- 2#
#mu_b and sig_b are the mean and variance of the slope across sites#
mu_b <- 4#
sig_b <- 1#
#draw S=10 site means for slope and intercept#
a_site <- rnorm(S,mu_a,sig_a)#
b_site <- rnorm(S,mu_b,sig_b)#
#draw S=10 site sds for slope and intercept (variability of plots within sites)#
sig_a_site <- rlnorm(S,0, sig_a)#
sig_b_site <- rlnorm(S,0, sig_b)#
#
#for each plot, draw the slope and intercept from the appropriate site mean and sd#
a_plot <- rep(0,J)#
b_plot <- rep(0,J)#
for (j in 1:J){#
  a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[sitenum[j]]);#
  b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[sitenum[j]]);#
}#
#
#draw three observations from each plot with sd = sig_y#
sig_y <- 1#
y <- rep(0,N)#
for (n in 1:N){#
  yhat[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n]#
  y[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n] + rnorm(1,0,sig_y)#
}#
#
#plot data#
allsites <- rep(c(1:10),each=12) #for plotting, list of site numbers for each obs#
plot(y~x,col=allsites,type='n')#
text(x,y,plotnum, cex=0.5, col=allsites)
dat <- list(N=N,S=S,J=J,plotnum=plotnum, sitenum=sitenum,y=y,x=x) #
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/threelevel_plotsinsites.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4, control=list(adapt_delta = 0.9))
launch_shinystan(fitme)
library(rstan)#
library(shinystan)#
#
nreps = 10  #replicate observations per plot#
S = 10     #total number of sites#
jreps <- 8#
J = jreps * S  #total number of plots (4 per site)#
N = nreps*jreps*S #
#
x <- rgamma(N,5,2)#
#
plotnum <- rep(c(1:J), each=nreps)   #list of plot numbers for each observation (length N)#
sitenum <- rep(c(1:S), each=jreps)  #list of site numbers for each plot (length J)#
#
#mu_a and sig_a are the mean and variance of the intercept across sites#
mu_a <- 5#
sig_a <- 2#
#mu_b and sig_b are the mean and variance of the slope across sites#
mu_b <- 4#
sig_b <- 1#
#draw S=10 site means for slope and intercept#
a_site <- rnorm(S,mu_a,sig_a)#
b_site <- rnorm(S,mu_b,sig_b)#
#draw S=10 site sds for slope and intercept (variability of plots within sites)#
sig_a_site <- rlnorm(S,0,1)#
sig_b_site <- rlnorm(S,0,1)#
#
#for each plot, draw the slope and intercept from the appropriate site mean and sd#
a_plot <- rep(0,J)#
b_plot <- rep(0,J)#
for (j in 1:J){#
  a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[sitenum[j]]);#
  b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[sitenum[j]]);#
}#
#
#draw three observations from each plot with sd = sig_y#
sig_y <- 1#
y <- rep(0,N)#
for (n in 1:N){#
  yhat[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n]#
  y[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n] + rnorm(1,0,sig_y)#
}#
#
#plot data#
allsites <- rep(c(1:10),each=12) #for plotting, list of site numbers for each obs#
plot(y~x,col=allsites,type='n')#
text(x,y,plotnum, cex=0.5, col=allsites)#
#
#call stan model#
dat <- list(N=N,S=S,J=J,plotnum=plotnum, sitenum=sitenum,y=y,x=x)
nreps = 10  #replicate observations per plot#
S = 10     #total number of sites#
jreps <- 8#
J = jreps * S  #total number of plots (4 per site)#
N = nreps*jreps*S #
#
x <- rgamma(N,5,2)
x
plotnum <- rep(c(1:J), each=nreps)   #list of plot numbers for each observation (length N)#
sitenum <- rep(c(1:S), each=jreps)  #list of site numbers for each plot (length J)
#mu_a and sig_a are the mean and variance of the intercept across sites#
mu_a <- 5#
sig_a <- 2#
#mu_b and sig_b are the mean and variance of the slope across sites#
mu_b <- 4#
sig_b <- 1#
#draw S=10 site means for slope and intercept#
a_site <- rnorm(S,mu_a,sig_a)#
b_site <- rnorm(S,mu_b,sig_b)#
#draw S=10 site sds for slope and intercept (variability of plots within sites)#
sig_a_site <- rlnorm(S,0,1)#
sig_b_site <- rlnorm(S,0,1)#
#
#for each plot, draw the slope and intercept from the appropriate site mean and sd#
a_plot <- rep(0,J)#
b_plot <- rep(0,J)#
for (j in 1:J){#
  a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[sitenum[j]]);#
  b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[sitenum[j]]);#
}#
#
#draw three observations from each plot with sd = sig_y#
sig_y <- 1#
y <- rep(0,N)#
for (n in 1:N){#
  yhat[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n]#
  y[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n] + rnorm(1,0,sig_y)#
}
#draw three observations from each plot with sd = sig_y#
sig_y <- 1#
y <- rep(0,N)#
yhat <- rep(0,N)#
for (n in 1:N){#
  yhat[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n]#
  y[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n] + rnorm(1,0,sig_y)#
}
#plot data#
allsites <- rep(c(1:10),each=12) #for plotting, list of site numbers for each obs#
plot(y~x,col=allsites,type='n')#
text(x,y,plotnum, cex=0.5, col=allsites)
library(rstan)#
library(shinystan)#
#
nreps = 10  #replicate observations per plot#
S = 10     #total number of sites#
jreps <- 8#
J = jreps * S  #total number of plots (4 per site)#
N = nreps*jreps*S #
#
x <- rgamma(N,5,2)#
#
plotnum <- rep(c(1:J), each=nreps)   #list of plot numbers for each observation (length N)#
sitenum <- rep(c(1:S), each=jreps)  #list of site numbers for each plot (length J)#
#
#mu_a and sig_a are the mean and variance of the intercept across sites#
mu_a <- 5#
sig_a <- 2#
#mu_b and sig_b are the mean and variance of the slope across sites#
mu_b <- 4#
sig_b <- 1#
#draw S=10 site means for slope and intercept#
a_site <- rnorm(S,mu_a,sig_a)#
b_site <- rnorm(S,mu_b,sig_b)#
#draw S=10 site sds for slope and intercept (variability of plots within sites)#
sig_a_site <- rlnorm(S,0,1)#
sig_b_site <- rlnorm(S,0,1)#
#
#for each plot, draw the slope and intercept from the appropriate site mean and sd#
a_plot <- rep(0,J)#
b_plot <- rep(0,J)#
for (j in 1:J){#
  a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[sitenum[j]]);#
  b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[sitenum[j]]);#
}#
#
#draw three observations from each plot with sd = sig_y#
sig_y <- 1#
y <- rep(0,N)#
yhat <- rep(0,N)#
for (n in 1:N){#
  yhat[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n]#
  y[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n] + rnorm(1,0,sig_y)#
}#
#
#plot data#
allsites <- rep(c(1:10),each=12) #for plotting, list of site numbers for each obs#
plot(y~x,col=allsites,type='n')#
text(x,y,plotnum, cex=0.5, col=allsites)#
#
#call stan model#
dat <- list(N=N,S=S,J=J,plotnum=plotnum, sitenum=sitenum,y=y,x=x)
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/Oahu2017/threelevel_plotsinsites_unpooledintercepts.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4, control=list(adapt_delta = 0.9))
launch_shinystan(fitme)
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/Oahu2017/threelevel_plotsinsites.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4, control=list(adapt_delta = 0.9, stepsize = 0.5)))
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/Oahu2017/threelevel_plotsinsites.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4, control=list(adapt_delta = 0.9, stepsize = 0.5))
launch_shinystan(fitme)
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/Oahu2017/threelevel_plotsinsites.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4, control=list(adapt_delta = 0.9, stepsize = 0.5))
library(rstan)#
library(shinystan)#
#
nreps = 20  #replicate observations per plot#
S = 10     #total number of sites#
nplots <- 8#
J = nplots * S  #total number of plots #
N = nreps*nplots*S #
#
x <- rgamma(N,5,2)#
#
plotnum <- rep(c(1:J), each=nreps)   #list of plot numbers for each observation (length N)#
sitenum <- rep(c(1:S), each=nplots)  #list of site numbers for each plot (length J)#
#
#mu_a and sig_a are the mean and variance of the intercept across sites#
mu_a <- 5#
sig_a <- 2#
#mu_b and sig_b are the mean and variance of the slope across sites#
mu_b <- 4#
sig_b <- 1#
#draw S=10 site means for slope and intercept#
a_site <- rnorm(S,mu_a,sig_a)#
b_site <- rnorm(S,mu_b,sig_b)#
# draw S=10 site sds for slope and intercept (variability of plots within sites)#
# sig_a_site <- rlnorm(S,0,1)#
# sig_b_site <- rlnorm(S,0,1)#
#OR draw a single sd for all sites#
sig_a_site <- rlnorm(1,0,1)#
sig_b_site <- rlnorm(1,0,1)#
#
#for each plot, draw the slope and intercept from the appropriate site mean and sd#
a_plot <- rep(0,J)#
b_plot <- rep(0,J)#
# for (j in 1:J){#
#   a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[sitenum[j]]);#
#   b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[sitenum[j]]);#
# }#
# Alternatively, assume same within-site variance for all sites#
for (j in 1:J){#
  a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[1]);#
  b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[1]);#
}#
#
#draw three observations from each plot with sd = sig_y#
sig_y <- 1#
y <- rep(0,N)#
yhat <- rep(0,N)#
for (n in 1:N){#
  yhat[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n]#
  y[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n] + rnorm(1,0,sig_y)#
}#
#
#plot data#
allsites <- rep(c(1:10),each=12) #for plotting, list of site numbers for each obs#
plot(y~x,col=allsites,type='n')#
text(x,y,plotnum, cex=0.5, col=allsites)#
#
#call stan model#
dat <- list(N=N,S=S,J=J,plotnum=plotnum, sitenum=sitenum,y=y,x=x) #
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/Oahu2017/new/threelevel_plotsinsites.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4, control=list(adapt_delta = 0.9, stepsize = 0.5))#
#
mu_a#
mu_b#
sig_a#
sig_b#
sig_y#
a_plot#
b_plot#
a_site#
b_site#
sig_a_site#
sig_b_site#
#
launch_shinystan(fitme)
fitme1 <- stan("~/Documents/git/teaching/stan/usefulcode/Oahu2017/threelevel_plotsinsites_unpooledintercepts.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4, control=list(adapt_delta = 0.9, stepsize = 0.5))
launch_shinystan(fitme)
launch_shinystan(fitme1)
#STAN example - plots in sites#
#
library(rstan)#
library(shinystan)#
#
nreps = 20  #replicate observations per plot#
S = 10     #total number of sites#
nplots <- 8#
J = nplots * S  #total number of plots #
N = nreps*nplots*S #
#
x <- rgamma(N,5,2)#
#
plotnum <- rep(c(1:J), each=nreps)   #list of plot numbers for each observation (length N)#
sitenum <- rep(c(1:S), each=nplots)  #list of site numbers for each plot (length J)#
#
#mu_a and sig_a are the mean and variance of the intercept across sites#
mu_a <- 5#
sig_a <- 2#
#mu_b and sig_b are the mean and variance of the slope across sites#
mu_b <- 4#
sig_b <- 1#
#draw S=10 site means for slope and intercept#
a_site <- rnorm(S,mu_a,sig_a)#
b_site <- rnorm(S,mu_b,sig_b)#
# draw S=10 site sds for slope and intercept (variability of plots within sites)#
# sig_a_site <- rlnorm(S,0,1)#
# sig_b_site <- rlnorm(S,0,1)#
#OR draw a single sd for all sites#
sig_a_site <- rlnorm(1,0,1)#
sig_b_site <- rlnorm(1,0,1)#
#
#for each plot, draw the slope and intercept from the appropriate site mean and sd#
a_plot <- rep(0,J)#
b_plot <- rep(0,J)#
# for (j in 1:J){#
#   a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[sitenum[j]]);#
#   b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[sitenum[j]]);#
# }#
# Alternatively, assume same within-site variance for all sites#
for (j in 1:J){#
  a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[1]);#
  b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[1]);#
}#
#
#draw three observations from each plot with sd = sig_y#
sig_y <- 1#
y <- rep(0,N)#
yhat <- rep(0,N)#
for (n in 1:N){#
  yhat[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n]#
  y[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n] + rnorm(1,0,sig_y)#
}#
#
#plot data#
allsites <- rep(c(1:10),each=12) #for plotting, list of site numbers for each obs#
plot(y~x,col=allsites,type='n')#
text(x,y,plotnum, cex=0.5, col=allsites)#
#
#call stan model#
dat <- list(N=N,S=S,J=J,plotnum=plotnum, sitenum=sitenum,y=y,x=x) #
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/Oahu2017/threelevel_plotsinsites.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4, control=list(adapt_delta = 0.9, stepsize = 0.5))#
#
mu_a#
mu_b#
sig_a#
sig_b#
sig_y#
a_plot#
b_plot#
a_site#
b_site#
sig_a_site#
sig_b_site#
#
launch_shinystan(fitme)
library(rstan)#
library(shinystan)#
#
nreps = 20  #replicate observations per plot#
S = 10     #total number of sites#
nplots <- 8#
J = nplots * S  #total number of plots #
N = nreps*nplots*S #
#
x <- rgamma(N,5,2)#
#
plotnum <- rep(c(1:J), each=nreps)   #list of plot numbers for each observation (length N)#
sitenum <- rep(c(1:S), each=nplots)  #list of site numbers for each plot (length J)#
#
#mu_a and sig_a are the mean and variance of the intercept across sites#
mu_a <- 5#
sig_a <- 2#
#mu_b and sig_b are the mean and variance of the slope across sites#
mu_b <- 4#
sig_b <- 1#
#draw S=10 site means for slope and intercept#
a_site <- rnorm(S,mu_a,sig_a)#
b_site <- rnorm(S,mu_b,sig_b)#
# draw S=10 site sds for slope and intercept (variability of plots within sites)#
# sig_a_site <- rlnorm(S,0,1)#
# sig_b_site <- rlnorm(S,0,1)#
#OR draw a single sd for all sites#
sig_a_site <- rlnorm(1,0,1)#
sig_b_site <- rlnorm(1,0,1)#
#
#for each plot, draw the slope and intercept from the appropriate site mean and sd#
a_plot <- rep(0,J)#
b_plot <- rep(0,J)#
# for (j in 1:J){#
#   a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[sitenum[j]]);#
#   b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[sitenum[j]]);#
# }#
# Alternatively, assume same within-site variance for all sites#
for (j in 1:J){#
  a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[1]);#
  b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[1]);#
}#
#
#draw three observations from each plot with sd = sig_y#
sig_y <- 1#
y <- rep(0,N)#
yhat <- rep(0,N)#
for (n in 1:N){#
  yhat[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n]#
  y[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n] + rnorm(1,0,sig_y)#
}#
#
#plot data#
allsites <- rep(c(1:10),each=12) #for plotting, list of site numbers for each obs#
plot(y~x,col=allsites,type='n')#
text(x,y,plotnum, cex=0.5, col=allsites)#
#
#call stan model#
dat <- list(N=N,S=S,J=J,plotnum=plotnum, sitenum=sitenum,y=y,x=x)
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/Oahu2017/threelevel_plotsinsites_unpooledintercepts.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4, control=list(adapt_delta = 0.9, stepsize = 0.5))
launch_shinystan(fitme)
print(fitme)
#call stan model#
dat <- list(N=N,S=S,J=J,plotnum=plotnum, sitenum=sitenum,y=y,x=x) #
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/Oahu2017/threelevel_plotsinsites.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4, control=list(adapt_delta = 0.9, stepsize = 0.5))
print(fitme)
launch_shinystan(fitme)
#call stan model#
dat <- list(N=N,S=S,J=J,plotnum=plotnum, sitenum=sitenum,y=y,x=x) #
fitme <- stan("~/Documents/git/teaching/stan/usefulcode/Oahu2017/threelevel_plotsinsites_unpooledintercepts.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4, control=list(adapt_delta = 0.9, stepsize = 0.5))
launch_shinystan(fitme)
mu_b
mu_b#
mu_a#
mu_b#
sig_a#
sig_b#
sig_y#
a_plot#
b_plot#
a_site#
b_site#
sig_a_site#
sig_b_site
launch_shinystan(fitme)
library(rstan)#
library(shinystan)#
#
nreps = 20  #replicate observations per plot#
S = 10     #total number of sites#
nplots <- 8#
J = nplots * S  #total number of plots #
N = nreps*nplots*S #
#
x <- rgamma(N,5,2)#
#
plotnum <- rep(c(1:J), each=nreps)   #list of plot numbers for each observation (length N)#
sitenum <- rep(c(1:S), each=nplots)  #list of site numbers for each plot (length J)#
#
#mu_a and sig_a are the mean and variance of the intercept across sites#
mu_a <- 5#
sig_a <- 2#
#mu_b and sig_b are the mean and variance of the slope across sites#
mu_b <- 4#
sig_b <- 1#
#draw S=10 site means for slope and intercept#
a_site <- rnorm(S,mu_a,sig_a)#
b_site <- rnorm(S,mu_b,sig_b)#
# draw S=10 site sds for slope and intercept (variability of plots within sites)#
# sig_a_site <- rlnorm(S,0,1)#
# sig_b_site <- rlnorm(S,0,1)#
#OR draw a single sd for all sites#
sig_a_site <- rlnorm(1,0,1)#
sig_b_site <- rlnorm(1,0,1)#
#
#for each plot, draw the slope and intercept from the appropriate site mean and sd#
a_plot <- rep(0,J)#
b_plot <- rep(0,J)#
# for (j in 1:J){#
#   a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[sitenum[j]]);#
#   b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[sitenum[j]]);#
# }#
# Alternatively, assume same within-site variance for all sites#
for (j in 1:J){#
  a_plot[j] <- rnorm(1,a_site[sitenum[j]], sig_a_site[1]);#
  b_plot[j] <- rnorm(1,b_site[sitenum[j]], sig_b_site[1]);#
}#
#
#draw three observations from each plot with sd = sig_y#
sig_y <- 1#
y <- rep(0,N)#
yhat <- rep(0,N)#
for (n in 1:N){#
  yhat[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n]#
  y[n] <- a_plot[plotnum[n]] + b_plot[plotnum[n]]*x[n] + rnorm(1,0,sig_y)#
}#
#
#plot data#
allsites <- rep(c(1:10),each=12) #for plotting, list of site numbers for each obs#
plot(y~x,col=allsites,type='n')#
text(x,y,plotnum, cex=0.5, col=allsites)
fitme.unpool <- stan("~/Documents/git/teaching/stan/usefulcode/Oahu2017/threelevel_plotsinsites_unpooledintercepts.stan", data=c("N","J","S","plotnum", "sitenum","y","x"), iter=4000, chains=4)
launch_shinystan(fitme_unpool)
launch_shinystan(fitme.unpool)
mu_a#
mu_b#
sig_a#
sig_b#
sig_y#
a_plot#
b_plot#
a_site#
b_site#
sig_a_site#
sig_b_site
launch_shinystan(fitme.unpool)
try<-read.csv("~/Desktop/goo.csv", header=TRUE)
head(try)
range(goo$TMAX)
range(try$TMAX)
try<-read.csv("~/Desktop/goo.csv", header=TRUE, na.strings=-9999)
hist(try$TMAX)
try<-read.csv("~/Desktop/goo.csv", header=TRUE, na.strings=-9999.0)
hist(try$TMAX)
df <- subset(try, TMAX>0)
hist(df$TMAX)
df <- subset(try, TMAX>-50)
hist(df$TMAX)
hist(df$TMAX, xmin="TMAX from Metv4 in Database_v4_05022016_IGCA ")
hist(df$TMAX, xlab="TMAX from Metv4 in Database_v4_05022016_IGCA")
hist(df$TMAX, xlab="TMAX from Metv4 in Database_v4_05022016_IGCA", main="")
goo1 <- read.csv("~/Documents/git/projects/vin/davis/data/ets/2016/juice/ETSLabsReport_10445_10142016.csv", header=TRUE)
goo2 <- read.csv("ETSLabsReport_10445_11212016.csv", header=TRUE)
goo2 <- read.csv("~/Documents/git/projects/vin/davis/data/ets/2016/juice/ETSLabsReport_10445_11212016.csv", header=TRUE)
head(goo2)
hist(goo2$Result)
par(mfrow=c(1,2))
hist(as.numeric(goo2$Result))
hist(as.numeric(goo1$Result))
unique(goo1$Analysis.Name)
unique(goo2$Analysis.Name)
sort(unique(goo2$Analysis.Name))
sort(unique(goo1$Analysis.Name))
subset(goo2, Analysis.name=="Comments")
subset(goo2, Analysis.Name=="Comments")
dim(goo1)
dim(goo2)
goo2 <- read.csv("~/Documents/git/projects/vin/davis/data/ets/2016/juice/ETSLabsReport_10445_11212016.csv", header=TRUE)
goo1 <- read.csv("~/Documents/git/projects/vin/davis/data/ets/2016/juice/ETSLabsReport_10445_10142016.csv", header=TRUE)
goo2 <- read.csv("~/Documents/git/projects/vin/davis/data/ets/2016/juice/ETSLabsReport_10445_11212016.csv", header=TRUE)
dim(goo2)
library(car)
?Anova
## Started 11 December 0216 ###
## By Lizzie, on a flight to SFO ###
## It's AGU time of year! ###
#
## This file reads in and cleans up climate data related to Adelaide data ###
#
## Updated 17 January 2017 to reference new folder structure ###
#
## See also wine.diversity.clim.maps.R ###
#
## set working directory#
setwd("~/Documents/git/projects/vin/climateadelaide/analyses")#
#
require(plyr,dplyr,tidyr)#
#
# Read in the tmin and tmax data using one cell#
# cc mean climcell (versus climgrid method)#
cc.max1 <- read.csv ("input/climate/wine_climcell_tmax_1951-1980.csv", header=TRUE)#
cc.max1$X <- NULL#
names(cc.max1) <- c("country", "winelat", "winelon", "crulat", "crulon", "1951", "1952", "1953", "1954",#
    "1955", "1956", "1957", "1958", "1959", "1960", "1961", "1962", "1963", "1964", "1965", "1966", "1967",#
    "1968", "1969", "1970", "1971", "1972", "1973", "1974","1975", "1976", "1977", "1978", "1979", "1980")#
#
cc.min1 <- read.csv ("input/climate/wine_climcell_tmin_1951-1980.csv", header=TRUE)#
cc.min1$X <- NULL#
names(cc.min1) <- c("country", "winelat", "winelon", "crulat", "crulon", "1951", "1952", "1953", "1954",#
    "1955", "1956", "1957", "1958", "1959", "1960", "1961", "1962", "1963", "1964", "1965", "1966", "1967",#
    "1968", "1969", "1970", "1971", "1972", "1973", "1974","1975", "1976", "1977", "1978", "1979", "1980")#
#
cc.max2 <- read.csv ("input/climate/wine_climcell_tmax_1986-2015.csv", header=TRUE)#
cc.max2$X <- NULL#
names(cc.max2) <- c("country", "winelat", "winelon", "crulat", "crulon", "1986", "1987", "1988", "1989",#
    "1990", "1991", "1992", "1993", "1994", "1995", "1996", "1997", "1998", "1999", "2000", "2001", "2002",#
    "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015" )#
#
cc.min2 <- read.csv ("input/climate/wine_climcell_tmin_1986-2015.csv", header=TRUE)#
cc.min2$X <- NULL#
names(cc.min2) <- c("country", "winelat", "winelon", "crulat", "crulon", "1986", "1987", "1988", "1989",#
    "1990", "1991", "1992", "1993", "1994", "1995", "1996", "1997", "1998", "1999", "2000", "2001", "2002",#
    "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015" )#
#
cc.min1.long <- gather(cc.min1, year, tmin, -country, -winelat, -winelon, -crulat, -crulon)#
cc.max1.long <- gather(cc.max1, year, tmax, -country, -winelat, -winelon, -crulat, -crulon)#
cc.min2.long <- gather(cc.min2, year, tmin, -country, -winelat, -winelon, -crulat, -crulon)#
cc.max2.long <- gather(cc.max2, year, tmax, -country, -winelat, -winelon, -crulat, -crulon)#
#
cc.1 <- inner_join(cc.min1.long, cc.max1.long, by=c("country", "winelat", "winelon", "crulat",#
    "crulon", "year"))#
cc.1$when <- "1951-1980"#
cc.2 <- inner_join(cc.min2.long, cc.max2.long, by=c("country", "winelat", "winelon", "crulat",#
    "crulon", "year"))#
cc.2$when <- "1986-2015"#
#
cc.minmax <-  rbind(cc.1, cc.2)#
#
# Read in the tmin and tmax data using grid method#
# cg mean climgrid (versus climcell method)#
#
cg.max1 <- read.csv ("input/climate/wine_climgrid_tmax_1951-1980.csv", header=TRUE)#
cg.max1$X <- NULL#
names(cg.max1) <- c("country", "winelat", "winelon", "crulat", "crulon", "1951", "1952", "1953", "1954",#
    "1955", "1956", "1957", "1958", "1959", "1960", "1961", "1962", "1963", "1964", "1965", "1966", "1967",#
    "1968", "1969", "1970", "1971", "1972", "1973", "1974","1975", "1976", "1977", "1978", "1979", "1980")#
#
cg.min1 <- read.csv ("input/climate/wine_climgrid_tmin_1951-1980.csv", header=TRUE)#
cg.min1$X <- NULL#
names(cg.min1) <- c("country", "winelat", "winelon", "crulat", "crulon", "1951", "1952", "1953", "1954",#
    "1955", "1956", "1957", "1958", "1959", "1960", "1961", "1962", "1963", "1964", "1965", "1966", "1967",#
    "1968", "1969", "1970", "1971", "1972", "1973", "1974","1975", "1976", "1977", "1978", "1979", "1980")#
#
cg.max2 <- read.csv ("climate/wine_climgrid_tmax_1986-2015.csv", header=TRUE)#
cg.max2$X <- NULL#
names(cg.max2) <- c("country", "winelat", "winelon", "crulat", "crulon", "1986", "1987", "1988", "1989",#
    "1990", "1991", "1992", "1993", "1994", "1995", "1996", "1997", "1998", "1999", "2000", "2001", "2002",#
    "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015" )#
#
cg.min2 <- read.csv ("input/climate/wine_climgrid_tmin_1986-2015.csv", header=TRUE)#
cg.min2$X <- NULL#
names(cg.min2) <- c("country", "winelat", "winelon", "crulat", "crulon", "1986", "1987", "1988", "1989",#
    "1990", "1991", "1992", "1993", "1994", "1995", "1996", "1997", "1998", "1999", "2000", "2001", "2002",#
    "2003", "2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013", "2014", "2015" )#
#
cg.min1.long <- gather(cg.min1, year, tmin, -country, -winelat, -winelon, -crulat, -crulon)#
cg.max1.long <- gather(cg.max1, year, tmax, -country, -winelat, -winelon, -crulat, -crulon)#
cg.min2.long <- gather(cg.min2, year, tmin, -country, -winelat, -winelon, -crulat, -crulon)#
cg.max2.long <- gather(cg.max2, year, tmax, -country, -winelat, -winelon, -crulat, -crulon)#
#
cg.1 <- inner_join(cg.min1.long, cg.max1.long, by=c("country", "winelat", "winelon", "crulat",#
    "crulon", "year"))#
cg.1$when <- "1951-1980"#
cg.2 <- inner_join(cg.min2.long, cg.max2.long, by=c("country", "winelat", "winelon", "crulat",#
    "crulon", "year"))#
cg.2$when <- "1986-2015"#
#
cg.minmax <-  rbind(cg.1, cg.2)
library(gdata) # for read.xls#
library(scales) # for alpha#
#
d <- read.xls("~/Documents/git/projects/treegarden/budreview/ospree/mergearchive/growthchambers_litreview_2016-06-16.xlsx", sheet=6)
tapply(d$temp_day, d$datasetID, mean)#
tapply(d$temp_night, d$datasetID, mean) #
#
d.cutt <- d[d$material == "cuttings",]#
d.cutt <- d.cutt[order(d.cutt$temp_day),]#
#
d.seed <- d[d$material != "cuttings",]#
d.seed <- d.seed[order(d.seed$temp_day),]
head(d)
# library(gdata) # for read.xls#
library(scales) # for alpha#
#
d <- read.csv("~/Documents/git/projects/treegarden/budreview/ospree/mergearchive/growthchambers_litreview_2016-06-16.csv", header=TRUE)
tapply(d$temp_day, d$datasetID, mean)
head(d)
tapply(d$forcetemp, d$datasetID, mean) # emw changed from temp_day#
tapply(d$forcetemp_night, d$datasetID, mean)
d.cutt <- d[d$material == "cuttings",]#
d.cutt <- d.cutt[order(d.cutt$temp_day),]#
#
d.seed <- d[d$material != "cuttings",]#
d.seed <- d.seed[order(d.seed$temp_day),]
par(mfrow = c(2, 1))#
#
plot(d.cutt$forcetemp, pch = "-", col = cols[1], cex = 2, #
	ylim = c(-5, 35),#
	xlab = "Study",#
	ylab = "Temp")#
points(d.cutt$forcetemp_night, pch = "-", col = cols[2], cex = 2)#
abline(h = mean(d.cutt[d.cutt$forcetemp != d.cutt$forcetemp_night,"forcetemp"]), col = cols[1], lty = 2)#
abline(h = mean(d.cutt[d.cutt$forcetemp != d.cutt$forcetemp_night,"forcetemp_night"]), col = cols[2], lty = 2)#
#
title(main = "Day/night temps by study")#
legend("topleft", bty = "n", "Cuttings")#
plot(d.seed$forcetemp, pch = "-", col = cols[1], cex = 2,#
	ylim = c(-5, 35),#
	xlab = "Study",#
	ylab = "Temp")#
points(d.seed$forcetemp_night, pch = "-", col = cols[2], cex = 2)#
abline(h = mean(d.seed[d.seed$forcetemp != d.seed$forcetemp_night,"forcetemp"]), col = cols[1], lty = 2)#
abline(h = mean(d.seed[d.seed$forcetemp != d.seed$forcetemp_night,"forcetemp_night"]), col = cols[2], lty = 2)#
legend("topleft", bty = "n", "Seedlings or other material")
cols = alpha(c("red", "blue"), 0.5)
tapply(d$forcetemp, d$datasetID, mean)#
tapply(d$forceforcetemp_night, d$datasetID, mean) #
#
d.cutt <- d[d$material == "cuttings",]#
d.cutt <- d.cutt[order(d.cutt$forcetemp),]#
#
d.seed <- d[d$material != "cuttings",]#
d.seed <- d.seed[order(d.seed$forcetemp),]#
#
cols = alpha(c("red", "blue"), 0.5)
head(d)
tapply(d$forcetemp_night, d$datasetID, mean)
d.cutt <- d[d$material == "cuttings",]#
d.cutt <- d.cutt[order(d.cutt$forcetemp),]#
#
d.seed <- d[d$material != "cuttings",]#
d.seed <- d.seed[order(d.seed$forcetemp),]#
#
cols = alpha(c("red", "blue"), 0.5)#
pdf("Lit review check.pdf", height = 8, width = 6)#
#
par(mfrow = c(2, 1))#
#
plot(d.cutt$forcetemp, pch = "-", col = cols[1], cex = 2, #
	ylim = c(-5, 35),#
	xlab = "Study",#
	ylab = "Temp")#
points(d.cutt$forcetemp_night, pch = "-", col = cols[2], cex = 2)#
abline(h = mean(d.cutt[d.cutt$forcetemp != d.cutt$forcetemp_night,"forcetemp"]), col = cols[1], lty = 2)#
abline(h = mean(d.cutt[d.cutt$forcetemp != d.cutt$forcetemp_night,"forcetemp_night"]), col = cols[2], lty = 2)#
#
title(main = "Day/night temps by study")#
legend("topleft", bty = "n", "Cuttings")#
plot(d.seed$forcetemp, pch = "-", col = cols[1], cex = 2,#
	ylim = c(-5, 35),#
	xlab = "Study",#
	ylab = "Temp")#
points(d.seed$forcetemp_night, pch = "-", col = cols[2], cex = 2)#
abline(h = mean(d.seed[d.seed$forcetemp != d.seed$forcetemp_night,"forcetemp"]), col = cols[1], lty = 2)#
abline(h = mean(d.seed[d.seed$forcetemp != d.seed$forcetemp_night,"forcetemp_night"]), col = cols[2], lty = 2)#
legend("topleft", bty = "n", "Seedlings or other material")
head(d.cutt)
plot(d.cutt$forcetemp, pch = "-", col = cols[1], cex = 2, #
	ylim = c(-5, 35),#
	xlab = "Study",#
	ylab = "Temp")
plot(d.cutt$forcetemp, 	ylim = c(-5, 35),#
	xlab = "Study",#
	ylab = "Temp")
plot(d.cutt$forcetemp, col = cols[1], cex = 2, #
	ylim = c(-5, 35),#
	xlab = "Study",#
	ylab = "Temp")
plot(d.cutt$forcetemp, pch = "-", col = cols[1], #
	ylim = c(-5, 35),#
	xlab = "Study",#
	ylab = "Temp")
pdf("Lit review check.pdf", height = 8, width = 6)#
#
par(mfrow = c(2, 1))#
#
plot(d.cutt$forcetemp, pch = "-", col = cols[1],  #
	ylim = c(-5, 35),#
	xlab = "Study",#
	ylab = "Temp")#
points(d.cutt$forcetemp_night, pch = "-", col = cols[2])#
abline(h = mean(d.cutt[d.cutt$forcetemp != d.cutt$forcetemp_night,"forcetemp"]), col = cols[1], lty = 2)#
abline(h = mean(d.cutt[d.cutt$forcetemp != d.cutt$forcetemp_night,"forcetemp_night"]), col = cols[2], lty = 2)#
#
title(main = "Day/night temps by study")#
legend("topleft", bty = "n", "Cuttings")#
plot(d.seed$forcetemp, pch = "-", col = cols[1],#
	ylim = c(-5, 35),#
	xlab = "Study",#
	ylab = "Temp")#
points(d.seed$forcetemp_night, pch = "-", col = cols[2])#
abline(h = mean(d.seed[d.seed$forcetemp != d.seed$forcetemp_night,"forcetemp"]), col = cols[1], lty = 2)#
abline(h = mean(d.seed[d.seed$forcetemp != d.seed$forcetemp_night,"forcetemp_night"]), col = cols[2], lty = 2)#
legend("topleft", bty = "n", "Seedlings or other material")
?aggregate
?as.matrix
as.dist
?as.dist
??as.data.frame
### Cat - Chapter 11 Exercise 4 - 7 Feb 2017#
library(arm)#
library(lme4)#
library(ggplot2)#
library(dplyr)#
library(tidyr)#
#
# Clear Workspace#
rm(list=ls()) #
options(stringsAsFactors=FALSE)
try <- gather()
goo <_ "Acer_rubrum,_stage_09sm"
goo <- "Acer_rubrum,_stage_09sm"
spname <- sub("_", " ", strsplit(goo))
spname <- sub("_", " ", strsplit(goo)[[1]][1])
goo
spname <- sub("_", " ", strsplit(goo, ",")[[1]][1])
spname
stages <- unlist(lapply(strsplit(goo, ","), function(x)#
                    x[2]))
stages
stages <- unlist(regmatches(stages, gregexpr("[0-9]{2}", stages)))
stages
stages <- sort(gsub("^[0]", "", stages))
stages
goo <- "Acer_rubrum,_stage_09sm"#
goo#
spname <- sub("_", " ", strsplit(goo, ",")[[1]][1])#
spname#
stages <- unlist(lapply(strsplit(goo, ","), function(x) x[2]))#
stages#
stages <- unlist(regmatches(stages, gregexpr("[0-9]{2}", stages)))#
stages#
stages <- sort(gsub("^[0]", "", stages)) # deleted this line!#
stages
data(cars)#
#
# fit a linear regression of distance on speed#
m <- lm( dist ~ speed , data=cars )#
#
# estimated coefficients from the model#
coef(m)#
#
# plot residuals against speed#
plot( resid(m) ~ speed , data=cars )
library(rethinking)
library(car)
?Anova
## R code 5.1#
# load data#
library(rethinking)#
data(WaffleDivorce)#
d <- WaffleDivorce
install.packages(c('devtools','coda','mvtnorm','loo'))#
library(devtools)#
install_github("rmcelreath/rethinking")
## R code 5.1#
# load data#
library(rethinking)#
data(WaffleDivorce)#
d <- WaffleDivorce
## R code 5.3#
d$Marriage.s <- (d$Marriage - mean(d$Marriage))/sd(d$Marriage)#
m5.2 <- map(#
    alist(#
        Divorce ~ dnorm( mu , sigma ) ,#
        mu <- a + bR * Marriage.s ,#
        a ~ dnorm( 10 , 10 ) ,#
        bR ~ dnorm( 0 , 1 ) ,#
        sigma ~ dunif( 0 , 10 )#
    ) , data = d )
prec(m5.3)
precis(m5.3)
precis(m5.2)
## R code 5.4#
m5.3 <- map(#
    alist(#
        Divorce ~ dnorm( mu , sigma ) ,#
        mu <- a + bR*Marriage.s + bA*MedianAgeMarriage.s ,#
        a ~ dnorm( 10 , 10 ) ,#
        bR ~ dnorm( 0 , 1 ) ,#
        bA ~ dnorm( 0 , 1 ) ,#
        sigma ~ dunif( 0 , 10 )#
    ) ,#
    data = d )#
precis( m5.3 )
# standardize predictor#
d$MedianAgeMarriage.s <- (d$MedianAgeMarriage-mean(d$MedianAgeMarriage))/#
    sd(d$MedianAgeMarriage)
## R code 5.3#
d$Marriage.s <- (d$Marriage - mean(d$Marriage))/sd(d$Marriage)#
m5.2 <- map(#
    alist(#
        Divorce ~ dnorm( mu , sigma ) ,#
        mu <- a + bR * Marriage.s ,#
        a ~ dnorm( 10 , 10 ) ,#
        bR ~ dnorm( 0 , 1 ) ,#
        sigma ~ dunif( 0 , 10 )#
    ) , data = d )#
#
precis(m5.2)
## R code 5.3#
d$Marriage.s <- (d$Marriage - mean(d$Marriage))/sd(d$Marriage)#
m5.2 <- map(#
    alist(#
        Divorce ~ dnorm( mu , sigma ) ,#
        mu <- a + bR * Marriage.s ,#
        a ~ dnorm( 10 , 10 ) ,#
        bR ~ dnorm( 0 , 1 ) ,#
        sigma ~ dunif( 0 , 10 )#
    ) , data = d )
## R code 5.3#
d$Marriage.s <- (d$Marriage - mean(d$Marriage))/sd(d$Marriage)#
m5.2 <- map(#
    alist(#
        Divorce ~ dnorm( mu , sigma ) ,#
        mu <- a + bR * Marriage.s ,#
        a ~ dnorm( 10 , 10 ) ,#
        bR ~ dnorm( 0 , 1 ) ,#
        sigma ~ dunif( 0 , 10 )#
    ) , data = d )#
#
precis(m5.3)
## R code 5.4#
m5.3 <- map(#
    alist(#
        Divorce ~ dnorm( mu , sigma ) ,#
        mu <- a + bR*Marriage.s + bA*MedianAgeMarriage.s ,#
        a ~ dnorm( 10 , 10 ) ,#
        bR ~ dnorm( 0 , 1 ) ,#
        bA ~ dnorm( 0 , 1 ) ,#
        sigma ~ dunif( 0 , 10 )#
    ) ,#
    data = d )#
precis( m5.3 )
plot( precis(m5.3) )
## R code 5.6#
m5.4 <- map(#
    alist(#
        Marriage.s ~ dnorm( mu , sigma ) ,#
        mu <- a + b*MedianAgeMarriage.s ,#
        a ~ dnorm( 0 , 10 ) ,#
        b ~ dnorm( 0 , 1 ) ,#
        sigma ~ dunif( 0 , 10 )#
    ) ,#
    data = d )
R code 5.7#
# compute expected value at MAP, for each State#
mu <- coef(m5.4)['a'] + coef(m5.4)['b']*d$MedianAgeMarriage.s#
# compute residual for each State#
m.resid <- d$Marriage.s - mu
## R code 5.8#
plot( Marriage.s ~ MedianAgeMarriage.s , d , col=rangi2 )#
abline( m5.4 )#
# loop over States#
for ( i in 1:length(m.resid) ) {#
    x <- d$MedianAgeMarriage.s[i] # x location of line segment#
    y <- d$Marriage.s[i] # observed endpoint of line segment#
    # draw the line segment#
    lines( c(x,x) , c(mu[i],y) , lwd=0.5 , col=col.alpha("black",0.7) )#
}
data(Howell1)#
d <- Howell1#
str(d)#
#
## R code 5.45#
m5.15 <- map(#
  alist(#
    height ~ dnorm( mu , sigma ) ,#
    mu <- a + bm*male ,#
    a ~ dnorm( 178 , 100 ) ,#
    bm ~ dnorm( 0 , 10 ) ,#
    sigma ~ dunif( 0 , 50 )#
  ) ,#
  data=d )#
precis(m5.15)#
#
## R code 5.46#
post <- extract.samples(m5.15)#
mu.male <- post$a + post$bm#
PI(mu.male)#
#
## R code 5.47#
m5.15b <- map(#
  alist(#
    height ~ dnorm( mu , sigma ) ,#
    mu <- af*(1-male) + am*male ,#
    af ~ dnorm( 178 , 100 ) ,#
    am ~ dnorm( 178 , 100 ) ,#
    sigma ~ dunif( 0 , 50 )#
  ) ,#
  data=d )#
#Check the estimates for this model:#
postb <- extract.samples(m5.15b)#
mu.maleb <- postb$am#
mu.femaleb <- postb$af#
PI(mu.maleb)#
PI(mu.femaleb)
?gl
nlabgroups = 10#
nsp = 80#
#
nforce== 10 # or make distribution?#
nphoto = 6#
nchill = 10#
#
rep = 10 # within each combination of treatments. #
#
ntot = nlabgroups*nforce*nphoto*nchill*rep # 792 rows; 22k rows across species
nforce = 10 # or make distribution?
ntot = nlabgroups*nforce*nphoto*nchill*rep # 792 rows; 22k rows across species
ntot
## Started 30 August 2016 ###
## By Lizzie ###
#
## Plots to look at the winegrape data ###
## Modified from https://github.com/lizzieinvancouver/buds/blob/c2956efd3d7a2f510adcd82e3e0a5c6502fd3add/analyses/Pheno%20Budburst%20analysis.R#
## See lines 328 and onward ##
#
## housekeeping#
rm(list=ls()) #
options(stringsAsFactors = FALSE)#
#
## libraries#
library(ggplot2)#
require(plyr); require(dplyr); require(tidyr) # data formatting#
#
## set working directory#
if(length(grep("Lizzie", getwd())>0)) {setwd("~/Documents/git/projects/vinmisc/heattolerance/analyses")#
}else #
setwd("~/GitHub/heattolerance/analyses/")#
#
## grab the data and merge them#
dater <- read.csv("input/phenmoist_grapes2016.csv", header=TRUE)#
ids <- read.csv("input/VitisExpReps2.csv", header=TRUE)#
#
dat <- subset(dater, is.na(Date)==FALSE & Date!="")#
#
# make some changes for the merge#
names(ids)[names(ids)=="Row"] <- "RowNum"#
names(ids)[names(ids)=="Plant"] <- "Num"#
names(ids)[names(ids)=="Variety"] <- "Var"#
ids.sm <- subset(ids, select=c("RowNum", "Num", "Var"))#
#
# merge the data#
d <- join(dat, ids.sm, by=c("RowNum", "Num")) #
#
# format date (see http://www.statmethods.net/input/dates.html)#
# And make it so we set day 0 to around the start of the experiment#
d$date <- as.Date(dat$Date, format="%m/%d/%Y")#
d$days <- as.numeric(format(d$date, "%j"))-228 # 228 is around 15 August#
#
# make a new column for days adjusted to sampling dateset#
# this correct for the fact that not all of the plants could be sampled in one day, so the code was calculating averages per day, and if the second day plants were not developing as quickly as the first day plants, it would look like the average was dropping#
d$sampleday <- d$days#
d$sampleday[d$sampleday == 8] <- 7#
d$sampleday[d$sampleday == 15] <- 14#
d$sampleday[d$sampleday == 18] <- 17#
d$sampleday[d$sampleday == 22] <- 21#
d$sampleday[d$sampleday == 25] <- 24#
d$sampleday[d$sampleday == 36] <- 35#
d$sampleday[d$sampleday == 66] <- 65#
d$sampleday[d$sampleday == 67] <- 65#
d$sampleday[d$sampleday == 74] <- 73#
d$sampleday[d$sampleday == 80] <- 79#
d$sampleday[d$sampleday == 87] <- 86#
d$sampleday[d$sampleday == 88] <- 86#
d$sampleday[d$sampleday == 94] <- 93#
#
# for now add the same treatment code to all, change to real treatments someday#
d$treatcode <- rep("notreat", nrow(d))#
#
# mean phen per plant#
print("Make sure the below is the two EL_stem columns!")#
head(d[,6:7])#
d$EL_mean <- rowMeans(d[,6:7], na.rm=TRUE) # careful! Relies on column numbers#
#
###
###
#
# plot(EL_stem1~date, data=d)#
#
###
colz <- c("darkred","mediumturquoise") # need to adjust how to use lcol#
lcol <- alpha(colz, 0.1)#
cepages <- sort(unique(d$Var))#
#
pdf(paste("graphs/VitisPheno", Sys.Date(), ".pdf", sep=""))#
#
par(mfcol=c(3, 4), mar = c(3,3,1,0.5))#
for(var in seq_along(cepages)){ # var <- 1#
  dx <- subset(d, Var==cepages[var])#
    unique(dx$sampleday) # need to switch to numeric for code to run#
    dx$sampleday <- as.numeric(dx$sampleday)#
  counter = 1#
  for(i in sort(as.character((unique(dx$treatcode))))){#
    dseq = seq(0, max(dx$sampleday))#
    # Will need to up above 10 when stages get higher!#
    plot(dseq, seq(0, 30, length=length(dseq)), type = "n", #
         ylab = "EL Stage",#
         xlab = "day", main=cepages[var])#
    # if(counter == 1) mtext(cepages, line = -2, adj = 0.5)#
    legend("topleft", bty="n",i, cex = 0.85, inset = 0)#
    xx <- dx[dx$treatcode == i,]#
    # calculate mean response by date#
    xt <- tapply(pmax(xx$EL_mean, na.rm=TRUE), list(xx$sampleday), mean, na.rm=TRUE)#
    for(j in unique(xx$Rep)){ #
      xj <- xx[xx$Rep == j,]#
      lines(xj$sampleday, xj$EL_mean, col = colz[2])#
    }#
    lines(rownames(xt), xt[], col = colz[1])#
    counter = counter + 1#
  }#
}#
dev.off()
